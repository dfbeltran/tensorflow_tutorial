{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPE_-_u0dEw"
      },
      "source": [
        "# Introduction to NLP Fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eysCvmmv08JX"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1AgVzUF1ALH",
        "outputId": "382112fa-ccc8-45bf-d6d2-3b3a9061c0ea"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fqszcV21Dun"
      },
      "source": [
        "## Get helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLyeqPf51L9Q",
        "outputId": "2c86293d-8c56-4f9f-b7b2-481967cb00c6"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-10 23:14:31--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-10 23:14:31 (61.7 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o5SsivJ1T0n"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle Introduction to NLP dataset (text samples of Tweets labelled as dister or not disaster)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhKsMCkN1wp4",
        "outputId": "ea3c323c-c9c0-4102-e534-9b158133d0d5"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-10 23:14:34--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.0.48, 172.217.1.208, 172.217.15.112, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.0.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip‚Äô\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-10-10 23:14:34 (13.7 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kh-LSYP1_0Q"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do would be to use Python. \n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Y4UFMTEb2gNP",
        "outputId": "8cea0dc3-70ce-43f8-ff67-9a5c5cf9a920"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Db7i_53M3sa_",
        "outputId": "4eec950c-10d1-4434-db0d-26ef2dbd17c3"
      },
      "source": [
        "# Shuffle trianing dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pR83ivx74Ghn",
        "outputId": "4304e5eb-323b-4ce7-8eeb-ed23d8c6c831"
      },
      "source": [
        "# What does the test dataframe look like\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETJ_0GkL4QW2",
        "outputId": "db6a8905-97b4-4c94-b7b4-a5988391aab4"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts(normalize=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.57034\n",
              "1    0.42966\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQx_mH1F47G_",
        "outputId": "aab12bae-9f92-499b-ad65-48c4eca58da9"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher that total num samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "    _, text, target = row\n",
        "    print(f'Target: {target}', '(real disaster)' if target > 0 else '(not real disaster)')\n",
        "    print(f'Text:\\n{text}\\n')\n",
        "    print('---\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Snowstorm planned outside #Rome's St Mary Major tonight - annual occasion artificial snow remembering summer snow in 358 AD on same spot.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "you could slit my throat and I'd apologize for bleeding on you\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@RebeccaforReal accepts Wisconsin Emergency Response Plan on behalf of @GovWalker #nbc15 http://t.co/Pis0aiVRbR\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "RT @LivingSafely: NWS posts Severe #Thunderstorm Warnings for parts of #AR #NC #OK. Seek strong shelter if at risk: http://t.co/kEa5l3b1AE\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "You will be held hostage by a radical group.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3tgijWC6JOm"
      },
      "source": [
        "## Split data into trianing and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3qse6r3-m0c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2BNL5ow-0m0"
      },
      "source": [
        "# Use train_test_split to split trianing data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'],\n",
        "                                                                            train_df_shuffled['target'],\n",
        "                                                                            test_size = 0.1, # use 10% data for val split\n",
        "                                                                            random_state = 42) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mw_e4R9_R0M",
        "outputId": "ce4e0105-8200-41ce-9477-8a01f6ed0f55"
      },
      "source": [
        "# Check the lenghts\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5yDW9E1_dxk",
        "outputId": "151ae8ee-53de-4031-ac7a-74d506183040"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5921    @mogacola @zamtriossu i screamed after hitting...\n",
              " 3904              Imagine getting flattened by Kurt Zouma\n",
              " 2804    @Gurmeetramrahim #MSGDoing111WelfareWorks Gree...\n",
              " 3718    @shakjn @C7 @Magnums im shaking in fear he's g...\n",
              " 1667    Somehow find you and I collide http://t.co/Ee8...\n",
              " 4435    @EvaHanderek @MarleyKnysh great times until th...\n",
              " 2544                     destroy the free fandom honestly\n",
              " 7223    Weapons stolen from National Guard Armory in N...\n",
              " 4265    @wfaaweather Pete when will the heat wave pass...\n",
              " 6568    Patient-reported outcomes in long-term survivo...\n",
              " Name: text, dtype: object, 5921    0\n",
              " 3904    0\n",
              " 2804    1\n",
              " 3718    0\n",
              " 1667    0\n",
              " 4435    1\n",
              " 2544    1\n",
              " 7223    0\n",
              " 4265    1\n",
              " 6568    1\n",
              " Name: target, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vNS4JPe_o28"
      },
      "source": [
        "## Converting text to numbers\n",
        "\n",
        "When dealing with text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are few ways to do this, namely:\n",
        "* Tokenization - direct mapping of token (a token could be a word or a character to number)\n",
        "* Embedding - Create a matrix of feature vector to each token (the size of the feature vector can be defined adn this embedding can be learned). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilAIeOzXeA1z"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY6XsKTqfQK6",
        "outputId": "c3acd35f-1267-4c96-f6ea-83195b86faa8"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5921    @mogacola @zamtriossu i screamed after hitting...\n",
              "3904              Imagine getting flattened by Kurt Zouma\n",
              "2804    @Gurmeetramrahim #MSGDoing111WelfareWorks Gree...\n",
              "3718    @shakjn @C7 @Magnums im shaking in fear he's g...\n",
              "1667    Somehow find you and I collide http://t.co/Ee8...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkaAfE03fRnM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None, # Create group of n-words\n",
        "                                    output_mode='int', # how to map token to numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be?\n",
        "                                    )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXL77BvVfjZT",
        "outputId": "f0ac3196-3cb7-4053-cfbe-8bbf627e73c6"
      },
      "source": [
        "# Find the average number of tokens (words) int the trianing tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8F-sSR-xSil"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to ahve in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaeGXQ-fx292"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgIQZPFSydv-",
        "outputId": "764fc4e2-0f87-4d3d-f572-3ffdef24e539"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM242c2Sy4ae",
        "outputId": "aca8956c-fe62-497a-9933-76f5748c92cb"
      },
      "source": [
        "# Choose a ranodm sentence from training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text: \\n {random_sentence} \\\n",
        "      \\n \\nVectorized version:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            " I will never support looting or the burning of buildings but when seeing the people fight back against the police. I was proud       \n",
            " \n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   8,   38,  192,  724, 2403,   53,    2,   86,    6,   95,   30,\n",
              "          45,  989,    2,   57]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KybClmXJze8O",
        "outputId": "b0be2b0e-89f1-4201-c3c9-bbf6652f4f66"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words  = words_in_vocab[-5:] # least common words\n",
        "print(f'Number of words in vocab:{len(words_in_vocab)}')\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f'5 least common words: {bottom_5_words}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab:10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Hqehh-0cKM"
      },
      "source": [
        "### Creating and Embedding using an Embedding Layer\n",
        "\n",
        "To make our emebedding, we're going to user TF Embedding Layer.\n",
        "\n",
        "The parameters we care most abour for our embedding layer:\n",
        "* `input_dim` = The size of our vocabulary\n",
        "* `output_dim` = The size of the output embedding vector, for example a value of a 100 would mean each token gets represented by a vector of 100 long.\n",
        "* `input_length` = length of sequences being passed to the embedding layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGGOpvDCpwL5",
        "outputId": "1cae199c-7adf-4538-dd30-c4aebdfd1696"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length, # set input shape\n",
        "                             output_dim = 128, # output shape\n",
        "                             embeddings_initializer = 'uniform', \n",
        "                             input_length = max_length, # how long is each input\n",
        "                             )\n",
        "\n",
        "embedding "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f488e875a10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPsuUDehrubY",
        "outputId": "04aaafc9-fbd2-446a-887d-377621cf2d91"
      },
      "source": [
        "# Get a random senteces from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text: \\n {random_sentence} \\\n",
        "        \\n \\n Embedded verison:')\n",
        "\n",
        "# Embed the random sentence (turn it into dense vector of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            " Families to sue over Legionnaires: More than 40 families affected by the fatal outbreak of Legionnaires' disea... http://t.co/81HVV3N3rS         \n",
            " \n",
            " Embedded verison:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-4.2723764e-02, -5.4419041e-05, -1.1071742e-02, ...,\n",
              "         -2.7405942e-02, -5.4445639e-03, -3.2623373e-02],\n",
              "        [ 6.4245090e-03,  4.2477611e-02, -3.2706037e-03, ...,\n",
              "         -3.1105591e-02,  4.0494550e-02,  4.2808224e-02],\n",
              "        [ 2.4101999e-02, -2.8186012e-02,  1.8832687e-02, ...,\n",
              "         -5.4300539e-03,  3.6775734e-02, -1.6044367e-02],\n",
              "        ...,\n",
              "        [-2.8103029e-02,  4.6884511e-02, -4.2112209e-02, ...,\n",
              "         -3.6690664e-02,  3.2403860e-02, -8.3427653e-03],\n",
              "        [ 1.4040265e-02,  2.5271144e-02, -4.3340363e-02, ...,\n",
              "         -1.3233554e-02, -2.3234356e-02, -3.3080459e-02],\n",
              "        [ 2.8412532e-02,  7.2720274e-03, -2.3067482e-03, ...,\n",
              "         -4.0883645e-03,  2.9895578e-02,  1.8992536e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFiR-09BsU84",
        "outputId": "b6ed7b79-dd12-4ece-c380-552aa77d7349"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-4.2723764e-02, -5.4419041e-05, -1.1071742e-02,  4.0284980e-02,\n",
              "        -3.0447423e-02, -2.4434507e-02,  2.0805087e-02,  3.2905173e-02,\n",
              "         3.4063365e-02,  4.4952940e-02,  7.7425353e-03,  4.4467915e-02,\n",
              "        -2.0347321e-02,  3.5413492e-02, -4.3269038e-02,  3.9714646e-02,\n",
              "         2.6216913e-02, -3.1502724e-02,  2.8959516e-02, -4.3084752e-02,\n",
              "        -2.3546070e-04, -4.7074329e-02, -2.7078832e-02, -2.5795901e-02,\n",
              "        -4.6517622e-02, -4.6599377e-02,  3.7145209e-02, -1.0971509e-02,\n",
              "        -3.7741542e-02, -1.3732184e-02, -2.7583266e-02, -3.8279545e-02,\n",
              "        -1.6261339e-02, -3.3228219e-02, -3.5865832e-02,  4.9698997e-02,\n",
              "        -1.6177129e-02,  3.9385010e-02, -2.2928441e-02,  3.1048406e-02,\n",
              "         1.8178586e-02,  3.9596107e-02,  4.1701172e-02, -2.2233760e-02,\n",
              "         3.2724962e-03,  3.6143791e-02, -1.3003923e-02,  2.1484978e-03,\n",
              "         3.4500387e-02, -3.3748068e-02,  4.4992566e-03,  2.1978904e-02,\n",
              "        -6.8293884e-04,  3.5257842e-02,  4.6939775e-04, -1.9082224e-02,\n",
              "        -1.0463476e-02, -1.6385831e-02, -6.7606084e-03,  1.9197132e-02,\n",
              "         1.5172135e-02, -3.2619752e-02,  2.1587584e-02, -4.2695887e-03,\n",
              "        -1.9785214e-02, -4.8659872e-02,  2.6360873e-02,  2.0993352e-03,\n",
              "         4.1395996e-02,  3.5225961e-02, -3.4565471e-02,  4.8508432e-02,\n",
              "        -3.4162819e-02,  2.5705483e-02, -1.5850805e-02,  3.5145473e-02,\n",
              "        -4.0167343e-02,  4.1703295e-02, -4.6599831e-02,  1.6808398e-03,\n",
              "        -3.5983644e-02,  2.7369861e-02, -2.3365701e-02, -3.6644243e-02,\n",
              "         4.5486342e-02,  1.2310289e-02, -4.1730702e-02,  4.2169083e-02,\n",
              "         3.3184234e-02,  3.0515566e-03, -3.9109267e-02, -4.5126628e-02,\n",
              "         3.7194695e-02,  1.6826738e-02,  1.1748530e-02,  2.8586164e-03,\n",
              "         2.2042815e-02, -4.1473530e-02, -1.8974829e-02,  2.6192907e-02,\n",
              "         2.5971223e-02,  2.0991277e-02,  4.0642586e-02, -4.7613308e-04,\n",
              "         1.7129492e-02, -1.4285434e-02,  4.3096412e-02, -4.9079310e-02,\n",
              "        -4.2255592e-02, -3.2041445e-02, -1.4521908e-02,  1.8889520e-02,\n",
              "         2.2668723e-02,  2.3785960e-02, -4.9159899e-03, -4.5599449e-02,\n",
              "        -1.3138998e-02,  8.5860975e-03,  4.9220588e-02, -4.3505430e-02,\n",
              "         4.1695502e-02, -4.7484349e-02,  4.6938691e-02, -3.4078598e-02,\n",
              "        -1.9381762e-02, -2.7405942e-02, -5.4445639e-03, -3.2623373e-02],\n",
              "       dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \"Families to sue over Legionnaires: More than 40 families affected by the fatal outbreak of Legionnaires' disea... http://t.co/81HVV3N3rS\")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOWdvKC5sxiZ"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network\n",
        "* Model 2: LSTM model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D convolutional neural netwrok (CNN)\n",
        "* Model 6: Tensorflow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data.\n",
        "\n",
        "How are we going to approach all of these?\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit a model \n",
        "* Evaluate a model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgBETxUX3KtV"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a becnhmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the Tf-idf formula to convert our words to numbers\n",
        "\n",
        "> üîë ** Note:** It's common practice to use non-DL algorithms as a baseline because of their speed and later using DL if you can improve upon them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSKqFAE07aXE"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvGv5lWJ72Vc",
        "outputId": "776609c6-3346-4485-ade6-3dc859f05699"
      },
      "source": [
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), #convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WxYd1L77_LC",
        "outputId": "79b64890-74cc-48fc-a3f7-4f13bff6a401"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f'Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWpTBVAD9IAi",
        "outputId": "98dadf34-9632-4015-af9e-f6cac956417a"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65MGE1wI8weR",
        "outputId": "ae49c302-69d8-4443-b908-a4a004a85633"
      },
      "source": [
        "train_df.target.value_counts(normalize=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.57034\n",
              "1    0.42966\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnc-HysVBHEI"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's prediction with different metrics every time, however, this would be cumbersome and could easily be fixed with a function\n",
        "\n",
        "Let's create one to compare our model's prediction with the truth label with the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn4_f0DnBBNf"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "    '''\n",
        "    Calculates model accuracy, precision, recall and F1-score of binary classification model.\n",
        "    '''\n",
        "    # Calculate model accuracy\n",
        "    model_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "    # Calculate model precision, recall and F1-score using \"weighted\" average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average = 'weighted')\n",
        "    model_results = {'accuracy':model_accuracy,\n",
        "                     'precision':model_precision*100,\n",
        "                     'recall':model_recall*100,\n",
        "                     'model_f1':model_f1*100}\n",
        "    return model_results"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd8UsbsL9DHS",
        "outputId": "8d23413f-74a0-42a1-925c-7cb154d68bea"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true = val_labels,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'model_f1': 78.6218975804955,\n",
              " 'precision': 81.11390004213173,\n",
              " 'recall': 79.26509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE11j1YSEhiP"
      },
      "source": [
        "### Model 1: Feed-forward neural network (dense model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc4C04h1wwBp"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save Tensorboard logs\n",
        "SAVE_DIR = 'model_logs'"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5klORh9zxB7J"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape =(1, ), dtype= tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn input text into numbers\n",
        "x = embedding(x) # turn numbers into embedding\n",
        "# x = layers.GlobalAveragePooling1D(name='global_average_pooling')(x)\n",
        "x = layers.GlobalMaxPool1D(name='global_max_pooling')(x) # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) # Create output layer, want binary outputs so use sigmoid\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RYlbg6wyLAb",
        "outputId": "50e6cb73-23f4-4738-d879-34527799048e"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_max_pooling (GlobalMa (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yZupFIoyTeh"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TISlx__aytRy",
        "outputId": "98d55aa2-2600-4b91-f7b4-aa3053962732"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x = train_sentences,\n",
        "                              y = train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                       experiment_name = 'model_1_dense')])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211010-231609\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 20ms/step - loss: 0.6356 - accuracy: 0.6490 - val_loss: 0.5708 - val_accuracy: 0.7598\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.4715 - accuracy: 0.8256 - val_loss: 0.4723 - val_accuracy: 0.7927\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.3425 - accuracy: 0.8780 - val_loss: 0.4497 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.2581 - accuracy: 0.9101 - val_loss: 0.4526 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1972 - accuracy: 0.9336 - val_loss: 0.4653 - val_accuracy: 0.7913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XsKPVbFzAra",
        "outputId": "a068d068-e6f9-47ae-b497-54eef7b3cc76"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46532729268074036, 0.7913385629653931]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qveBH4nyzQqJ",
        "outputId": "ac3d39dd-ea8b-45f4-b885-191097efa4a6"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT1jtk2BzVhJ",
        "outputId": "5081e900-1444-4875-8a98-c681d00a1baf"
      },
      "source": [
        "# look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40794387], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI4rnVFe00aS",
        "outputId": "424e1c87-6222-4941-cd0f-9ca09a85e069"
      },
      "source": [
        "# Look at the first 10 preds\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40794387],\n",
              "       [0.8590145 ],\n",
              "       [0.99398243],\n",
              "       [0.06834802],\n",
              "       [0.19819999],\n",
              "       [0.9559652 ],\n",
              "       [0.8955252 ],\n",
              "       [0.9884811 ],\n",
              "       [0.9319416 ],\n",
              "       [0.089647  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrcuYdoa07ph",
        "outputId": "45533392-9189-4a7e-d629-3f4e854dabe2"
      },
      "source": [
        "# convert model predictions probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUSUvJve1UHj",
        "outputId": "f916f1fb-fd22-4c6a-bf85-8af17d58a449"
      },
      "source": [
        "# Calculate our model_1 results \n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred= model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.13385826771653,\n",
              " 'model_f1': 78.83318764387542,\n",
              " 'precision': 79.6653347825067,\n",
              " 'recall': 79.13385826771653}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocKnJ1Iz1xkJ"
      },
      "source": [
        "## Visualizing learned embeddings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7ceIPfj2rTA",
        "outputId": "acda87e5-6dec-44b0-9b73-c85ab2dda552"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUFNNyrz26ay",
        "outputId": "295769ca-112f-4aa8-ff89-1cfbdd28217b"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_max_pooling (GlobalMa (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCpFNA4J3BQI",
        "outputId": "51c4393a-2d35-46b4-b866-454262a49d4f"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical reprsentations of each token in our training data, which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer('embedding').get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (output dim of embedding layer)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLkCFmuW3UDJ"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, lets see how we can visualize it.\n",
        "\n",
        "To do so, Tensorflow has a handy tool called Tensorflow projector: https://projector.tensorflow.org/\n",
        "\n",
        "And Tensorflow also has an incredible guide on word embeddings: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bzUoJkq3Uz5"
      },
      "source": [
        "# Create embedding files (we got this from Tensorflow Words embedding documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MAEqXiPH6z7p",
        "outputId": "24e9b924-7878-49c7-e700-b88b35425010"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f24c663c-4189-4576-bec2-6207c0a7d0aa\", \"vectors.tsv\", 16008438)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b841c2b3-3903-4205-95bc-f4d127204393\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nmcAzQp7x5q"
      },
      "source": [
        "## Recurrent neural network (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgNBKXJpj4cA"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = Long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our strucutre of an RNN typically looks like this:\n",
        "```\n",
        "Input (text) -> tokenize -> embedding -> layers (RNNs/Dense) -> Output (label probability)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zU4wfElkHYB"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1,), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True, )(x) # when you're stacking RNN cells together, you need to return sequence s\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name = 'model_2_LSTM')\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1sr5AovlUM5",
        "outputId": "fed8ffcc-1d92-4c78-a1a1-172329cf8142"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozo1bSkxoM7I"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX4EAsT2oYyg",
        "outputId": "9d589f23-cbb3-42df-8366-881dc0dcee0a"
      },
      "source": [
        "# Fit the model\n",
        "model_2.fit(x = train_sentences,\n",
        "            y = train_labels,\n",
        "            epochs = 5,\n",
        "            validation_data = (val_sentences, val_labels),\n",
        "            callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
        "                                                     'model_2_LSTM')])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211010-235555\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 32ms/step - loss: 0.3842 - accuracy: 0.8291 - val_loss: 0.4734 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.2513 - accuracy: 0.8983 - val_loss: 0.5312 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.1806 - accuracy: 0.9334 - val_loss: 0.5841 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.1374 - accuracy: 0.9512 - val_loss: 0.6326 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.1082 - accuracy: 0.9631 - val_loss: 0.8022 - val_accuracy: 0.7520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4893b45b90>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7lsbAYMombQ",
        "outputId": "6874802f-47ac-4929-87fd-e8a5366a6889"
      },
      "source": [
        "# make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20830902],\n",
              "       [0.95058036],\n",
              "       [0.9998549 ],\n",
              "       [0.08066821],\n",
              "       [0.04295838],\n",
              "       [0.9999249 ],\n",
              "       [0.8514508 ],\n",
              "       [0.9999801 ],\n",
              "       [0.9999541 ],\n",
              "       [0.72175884]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bTzYWgpo0Lv",
        "outputId": "b5da4a06-9411-488a-ad46-35eb72842d65"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqFFcnCwo_Tw",
        "outputId": "0d58881b-0eb2-4cbb-ce60-62181e72fcdd"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred = model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.19685039370079,\n",
              " 'model_f1': 75.23735887402714,\n",
              " 'precision': 75.39200264275287,\n",
              " 'recall': 75.19685039370079}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjajoiERvtPd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}