{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_SkimLit_NLP_milestone_project_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3EWMp09aauJ"
      },
      "source": [
        "# Milestone Project 2: SkimLit ðŸ“„ðŸ”¥\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
        "\n",
        "The paper we're replicating (the source of the data set we'll be using is avaiable here https://arxiv.org/abs/1710.06071)\n",
        "\n",
        "And reading through the paper above, we see that the model architecture that they use to achieve their best results is available here: https://arxiv.org/abs/1612.05251"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNjno2O9yaXP"
      },
      "source": [
        "## Confirm access to a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okg0-TEgyzEY",
        "outputId": "aa24d2eb-2554-49f4-e248-4183815052f4"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-63df1804-cbfb-0fb1-8951-acc8ca538d5d)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F6urrJkzfmQ"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200K RCT), let's download the dataset they used.\n",
        "\n",
        "We can do so from the authors GitHub. https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYaqxphIz-Rv",
        "outputId": "0d015d22-3076-4345-987b-e6b6637261ce"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5SG7HWm0FzH",
        "outputId": "7c3bcc5b-e990-4c14-cf6b-9ddb5885df94"
      },
      "source": [
        "# Check wat files are in the PubMed_20K_dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\n",
        "!ls pubmed-rct/PubMed_20k_RCT/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n",
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wY5iUv907eI"
      },
      "source": [
        "# Start our experiments using the 20K dataset with numbers replaced by \"@\" \n",
        "data_dir  = '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ETAvlI2N6_",
        "outputId": "9a5c6f5e-da0f-41b8-bb85-3d67a15dc2aa"
      },
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrcAD6H62Xev"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "And one of the best ways to become one with the data is to...\n",
        "\n",
        "> Visualize, visualize, visualize\n",
        "\n",
        "So with that in mind let's write a function to read in all of the lines of a target text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2twObcj3Dov"
      },
      "source": [
        "# Create a function to read the lines of a document\n",
        "\n",
        "def get_lines(filename):\n",
        "    '''\n",
        "    Reads filename (a text filename) and returns the lines of text as a list.\n",
        "\n",
        "    Args:\n",
        "        filename: a string contianing the target filepath\n",
        "\n",
        "    Returns:\n",
        "        A list of strings with one string per line from the target filename.\n",
        "    '''\n",
        "    with open(filename, 'r') as f:\n",
        "        return f.readlines()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv_NWIUz3qhP"
      },
      "source": [
        "# Let's read in the training lines\n",
        "train_lines = get_lines(data_dir+'train.txt') # read the lines within the training file"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pmmmTu-4BBY"
      },
      "source": [
        "Let's think about how we wnat our data to look...\n",
        "\n",
        "How I think our data would be best represented... \n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "    'target':  'BACKGROUND',\n",
        "    'text':  <TEXT>,\n",
        "    'total_lines': 11},\n",
        "    ...]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iaku2vd1BHOv"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "    '''\n",
        "    Returns a list of dictonaries of abstact line data.\n",
        "\n",
        "    Takes in filename, read it contents and sorts through each line,\n",
        "    extracting things like the target label, the text of senteces,\n",
        "    how many sentences are in the current abstract and what sentence number the target\n",
        "    is\n",
        "    '''\n",
        "    input_lines = get_lines(filename) #get all lines from filename\n",
        "    abstract_lines = '' #create an empty abstract\n",
        "    abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "    # Loop through each line in the target file\n",
        "    for line in input_lines:\n",
        "        if line.startswith('###'): #check to see if the string is an ID line\n",
        "            abstract_id = line\n",
        "            abstract_lines = '' # reset the abstract string if the line is an ID line\n",
        "\n",
        "        elif line.isspace(): # check to se if line is a new line\n",
        "            abstract_line_split = abstract_lines.splitlines() # split abstract into separte lines\n",
        "\n",
        "            # iterate them through each line in a single abstract and count them at the same time\n",
        "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "                line_data = {} # create emtpy dict for each line\n",
        "                target_text_split = abstract_line.split('\\t') #split target label from text\n",
        "                \n",
        "                line_data['target'] = target_text_split[0] # get target label\n",
        "                line_data['text'] = target_text_split[1].lower() # get target text and lower it\n",
        "                line_data['line_number'] = abstract_line_number #what number line does the line appear in our abstract\n",
        "                line_data['total_lines'] = len(abstract_line_split)-1 # How many total lines are in the target abstract (start from 0)\n",
        "                abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "        else: # if the above conditions aren't fullfilled, the line contains a labelled sentece\n",
        "            abstract_lines += line\n",
        "    return abstract_samples"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7284S0VcBG7v",
        "outputId": "ab05d16e-81e6-46ab-f4c1-73a849d49a65"
      },
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir+'/train.txt')\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir+'/dev.txt') #dev is another way to call it\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir+'/test.txt') \n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 558 ms, sys: 112 ms, total: 670 ms\n",
            "Wall time: 670 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W25GWuYLHcsN",
        "outputId": "d263679d-656b-466b-a273-d4da578d96a6"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 1,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzuhPyxcViA_"
      },
      "source": [
        "Now that our data is the format of a list of dictonaries, how about we run it inot a DataFrame to further visualize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "WGulDSadHnq2",
        "outputId": "69a4c2b4-032e-45bb-c7ae-0e7f6064be5d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "\n",
        "train_df.head(14)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8fqa0dDVxle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8489c56b-0388-46dd-aed6-343c67e96136"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "vojGNiyLtxcp",
        "outputId": "efbf1bfd-5077-462f-d1bc-4ec731360d7c"
      },
      "source": [
        "# Let's check the length of different lines\n",
        "train_df.total_lines.plot.hist()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff23d9ae2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boGyb0NIuFhJ"
      },
      "source": [
        "### Get lists of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWw80dRguLpo",
        "outputId": "f94e3005-4f86-4cf5-a128-2ea89639f04d"
      },
      "source": [
        "# Convert abstract text lines into lists\n",
        "\n",
        "train_sentences = train_df['text'].tolist()\n",
        "val_sentences = val_df['text'].tolist()\n",
        "test_sentences = test_df['text'].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE5ANAmiufAa",
        "outputId": "38799346-d0e7-4206-ec83-67869f3f6d91"
      },
      "source": [
        "# View the 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvoL-qeSukBf"
      },
      "source": [
        "### Make numeric labels (ML models requiere numeric labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uMRwXRBxmTp",
        "outputId": "0ddcc781-0e99-494c-de10-6fc7bc6fa320"
      },
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse = False) # We want a non-sparse matrix\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform((val_df['target']).to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform((test_df['target']).to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what one got encoded labels look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIwPnwLh07G3"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cY_wdaS1RcI",
        "outputId": "e348dc1f-5102-424e-a5c1-3a79c020a192"
      },
      "source": [
        "# Extract labels ('target' columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAhg9__812NA",
        "outputId": "6e819cde-275c-409a-983b-2da7ede96fd0"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l3ky5FiPoRK"
      },
      "source": [
        "## Starting a series of modelling experiments...\n",
        "\n",
        "As usual we're going to be trying out a bunch of different models and seeing which one works best.\n",
        "\n",
        "And as always, we're going to start with a baseline (TF-IDF Multinomial Naive BAyes classifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM51sBa02HX5"
      },
      "source": [
        "## Model 0: Getting a baseline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMmZe89LP4by",
        "outputId": "5712611e-f57b-4d79-e29d-bd76ae31fc15"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "                    ('tf-idf', TfidfVectorizer()),\n",
        "                    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "\n",
        "model_0.fit(X = train_sentences,\n",
        "            y = train_labels_encoded)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf-idf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1LRR_xEQO9C",
        "outputId": "b35e6a6e-e920-4690-f5e4-ef1fbae181cc"
      },
      "source": [
        "# Evaluate baseline model on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y = val_labels_encoded)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDDcg-pTRN4q",
        "outputId": "432a5ee8-c70d-4543-e207-e4d60ee8b81c"
      },
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFmrsBnyRXey"
      },
      "source": [
        "### Download helper function script\n",
        "In the previous module we wrote a function to compare predictions across different metrics (accuracy, preicison, recall and f1) and rather than rewriting here, let's download it from  our helper functions git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHIvU06tRvSq",
        "outputId": "9026f821-13e6-4130-a56b-47420203e544"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-20 02:23:44--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-20 02:23:44 (54.5 MB/s) - â€˜helper_functions.pyâ€™ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl1fQ0FORxUC"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQokUoKTRbRS",
        "outputId": "25e8f557-a453-4025-91f4-7c74129de3b7"
      },
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnuTjaJ4Sdaa"
      },
      "source": [
        "## Preparing our data (the text) for deep sequence models\n",
        "\n",
        "Before we start bulding deeper models, we've got to create vectorization an embedding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwmE4mBnSmQh"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67jY_aCBTDBS",
        "outputId": "2a867cd9-c593-4ee8-9ea3-0776b04fb644"
      },
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Zqii3X4pZsoz",
        "outputId": "a020365e-6e46-440f-f96a-b9b080437b2d"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins = 20);"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dCOl8XmSGaq",
        "outputId": "a73fe14c-7b0c-4cd2-d14b-725a55823e2e"
      },
      "source": [
        "# How long of a sentences lenght covers 95% of examples?\n",
        "output_seq_len = int(np.quantile(sent_lens, 0.95))\n",
        "output_seq_len"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5zQR4WmaFdy",
        "outputId": "551aa739-05df-44d5-acf0-ed0b8795132c"
      },
      "source": [
        "# Maximum sequence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCOu0lgZbUNy"
      },
      "source": [
        "### Create text vectorizer layer\n",
        "\n",
        "We want to make a layer which maps our text from words to number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hMM8Gx-ai06"
      },
      "source": [
        "# How many words are in our vocab? (taken from table 2 in paper)\n",
        "max_tokens = 68000\n",
        "\n",
        "# Create text vectorizer\n",
        "text_vectorizer =   layers.TextVectorization(max_tokens= max_tokens, # number of words in vocabulary\n",
        "                                            output_sequence_length = output_seq_len, # desired output lenght\n",
        "                                             )"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sg2PoIndD-z"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bl5zGOKdzzC",
        "outputId": "7a741a54-5c9e-4d40-dded-166ebac1f4be"
      },
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f'Text:\\n {target_sentence}')\n",
        "print(f'\\nLength of text: {len(target_sentence.split())}')\n",
        "print(f'\\nVectorized text: {text_vectorizer([target_sentence])}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            " at two weeks , the accelerated group initiated wrist/forearm passive range of motion and strengthening exercises , whereas the standard group initiated passive range of motion and strengthening at six weeks postoperatively .\n",
            "\n",
            "Length of text: 33\n",
            "\n",
            "Vectorized text: [[   15    51    53     2  3252    13  2137 41768  2241   283     4  1322\n",
            "      3  4136  1111   436     2   165    13  2137  2241   283     4  1322\n",
            "      3  4136    15   356    53   721     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-hLz7lteUAz",
        "outputId": "b51b6d8a-5b8d-482a-a6b6-bb1062f955d6"
      },
      "source": [
        "# How many words in our training vocabulary\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f'Number of words in vocab: {len(rct_20k_text_vocab)}')\n",
        "print(f'Most common words in the vocab: {rct_20k_text_vocab[:5]}')\n",
        "print(f'Least common words in the vocab: {rct_20k_text_vocab[-5:]}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 64841\n",
            "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPv8lVWIfZjR",
        "outputId": "98b9077e-9495-4cc3-ec8b-b0aec23377aa"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1Lf2H0cfqzz"
      },
      "source": [
        "### Create customtext embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VP455H5iVWb"
      },
      "source": [
        "# Create token emebedding\n",
        "token_embedding = layers.Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                                   output_dim = 128, # Note different embedding sizes results in drastically different numbers of params\n",
        "                                   mask_zero = True, # use masking to handle variables sequences lengths(save space)\n",
        "                                   name = 'token_embedding'\n",
        "                                   )"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch0U9IKAjyUc",
        "outputId": "87dfb04b-9e69-4984-fd7d-b5cfe2fe92ae"
      },
      "source": [
        "# show example embedding\n",
        "print(f'Sentence before vectorization: \\n {target_sentence}\\n')\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f'Sentence after vectorization: \\n {vectorized_sentence}\\n')\n",
        "embedded_sentence = token_embedding(vectorized_sentence)\n",
        "print(f'Sentence after embedding: \\n {embedded_sentence}\\n')\n",
        "print(f'Embedded sentence shape: \\n {embedded_sentence.shape}\\n')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization: \n",
            " at two weeks , the accelerated group initiated wrist/forearm passive range of motion and strengthening exercises , whereas the standard group initiated passive range of motion and strengthening at six weeks postoperatively .\n",
            "\n",
            "Sentence after vectorization: \n",
            " [[   15    51    53     2  3252    13  2137 41768  2241   283     4  1322\n",
            "      3  4136  1111   436     2   165    13  2137  2241   283     4  1322\n",
            "      3  4136    15   356    53   721     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Sentence after embedding: \n",
            " [[[ 0.04949117 -0.03016916  0.04363428 ...  0.04730261 -0.02594867\n",
            "   -0.01772605]\n",
            "  [ 0.0438489   0.00088765 -0.03333392 ...  0.0423533  -0.03733715\n",
            "   -0.03153791]\n",
            "  [ 0.04993869  0.01450094  0.03026697 ... -0.0082496  -0.04043053\n",
            "    0.02982017]\n",
            "  ...\n",
            "  [-0.04280632 -0.01759912 -0.00356656 ...  0.02076245 -0.02138161\n",
            "    0.02463367]\n",
            "  [-0.04280632 -0.01759912 -0.00356656 ...  0.02076245 -0.02138161\n",
            "    0.02463367]\n",
            "  [-0.04280632 -0.01759912 -0.00356656 ...  0.02076245 -0.02138161\n",
            "    0.02463367]]]\n",
            "\n",
            "Embedded sentence shape: \n",
            " (1, 55, 128)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAtY1oFylVwd"
      },
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "We're going to setup our data to run as fast as possible with the Tensorflow tf.data.API \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWLjJ2a6ltFd",
        "outputId": "c95d4088-2dde-4a30-c0e5-0af6084754a7"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ddig3j7nDpU",
        "outputId": "a4653f9a-f886-41ef-cf0f-1185d7c586f3"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqf7jMpGked2"
      },
      "source": [
        "## Model 1: Conv1d with token embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExrXmiFvoVUU",
        "outputId": "88f88b2c-cc58-4346-af0a-0eb5e0873d51"
      },
      "source": [
        "# Create 1D conv model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # Vectorize text inputs\n",
        "token_embed = token_embedding(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(token_embed)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector from conv layer\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHmi5hAAp4km",
        "outputId": "ae8e3e0b-d5bf-47ed-d913-7b9ce4a2acd9"
      },
      "source": [
        "# Fit the model\n",
        "history_model_1  = model_1.fit(train_dataset,\n",
        "                               epochs = 3,\n",
        "                               steps_per_epoch = int(0.1*len(train_dataset)),\n",
        "                               validation_data = valid_dataset,\n",
        "                               validation_steps = int(0.1*len(valid_dataset)) # only validate on 10% of batches\n",
        "                               )"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 37s 14ms/step - loss: 0.9111 - accuracy: 0.6405 - val_loss: 0.6898 - val_accuracy: 0.7360\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.6652 - accuracy: 0.7522 - val_loss: 0.6401 - val_accuracy: 0.7680\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.6233 - accuracy: 0.7707 - val_loss: 0.6009 - val_accuracy: 0.7816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1itDOLW2q49f",
        "outputId": "27977e1a-3485-4dcd-8e0c-d5d83808780c"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 5ms/step - loss: 0.6035 - accuracy: 0.7855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6034635901451111, 0.7855488061904907]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmSzEiy3r2bu",
        "outputId": "c092a047-0b7b-4fc1-bc1f-5632b50e3a94"
      },
      "source": [
        "# Make predictions (our model predicts prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs, model_1_pred_probs.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4.49068606e-01, 1.73953205e-01, 7.49754533e-02, 2.71624088e-01,\n",
              "         3.03787142e-02],\n",
              "        [4.02880162e-01, 3.30133975e-01, 1.40139805e-02, 2.44678989e-01,\n",
              "         8.29289760e-03],\n",
              "        [1.72702357e-01, 9.26395226e-03, 3.09436489e-03, 8.14896703e-01,\n",
              "         4.25501566e-05],\n",
              "        ...,\n",
              "        [8.24419931e-06, 1.21502369e-03, 9.13355034e-04, 2.49628056e-06,\n",
              "         9.97860849e-01],\n",
              "        [5.45918643e-02, 4.97471839e-01, 8.47485736e-02, 6.44620806e-02,\n",
              "         2.98725605e-01],\n",
              "        [1.82288080e-01, 6.20173514e-01, 4.95321639e-02, 7.89793134e-02,\n",
              "         6.90268353e-02]], dtype=float32), (30212, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8S3wyEQsAMV",
        "outputId": "52eae35d-9bb8-4419-f868-dcfcccce1cb6"
      },
      "source": [
        "# convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis = 1)\n",
        "model_1_preds"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMjSKn93sNOc",
        "outputId": "5d4ec4b7-c56e-4831-f69b-3d20cf109f36"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.55487885608368,\n",
              " 'f1': 0.7830165258838914,\n",
              " 'precision': 0.7823115937371249,\n",
              " 'recall': 0.7855487885608368}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToOSE4N-shP1",
        "outputId": "6d933f87-9e7b-443f-ea3f-0308425cc0cc"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbQLLcE9tu2W"
      },
      "source": [
        "## Model 2 : Feature extraction with pretrained token embeddings\n",
        "\n",
        "Now let's use pretrained word embeddings from TensorFlow Hub more specifically from Universal sentence encoder \n",
        "\n",
        "The paper originally used GloVe embeddings, however we're going to stick with the later created USE word embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW-Vy6NktMNV"
      },
      "source": [
        "# Download pretrained Tensorflow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name = 'universal_sentence_encoder')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRJ2gfuusmLV",
        "outputId": "827d4d9e-2568-4cbc-e01b-e765136ce7e6"
      },
      "source": [
        "# Test out pretrained embedding on a random sentence\n",
        "random_train_sentence = random.choice(train_sentences)\n",
        "print(f'Random sentences:\\n {random_train_sentence}')\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
        "print(f'Sentence after embedding: \\n{use_embedded_sentence[0][:13]}\\n')\n",
        "print(f'Length of sentence embedding: \\n{len(use_embedded_sentence[0])}\\n')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentences:\n",
            " at each session , ocular fixation data were collected during presentation of video stimuli of @ human faces .\n",
            "Sentence after embedding: \n",
            "[ 0.06857753  0.0649254  -0.00769766  0.017733    0.04212201  0.02778012\n",
            "  0.00583737  0.08185408 -0.0731161   0.06385659  0.0285299   0.05486455\n",
            "  0.02266908]\n",
            "\n",
            "Length of sentence embedding: \n",
            "512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR7NGqa7vlFV"
      },
      "source": [
        "### Building and fitting an NLP feature extraction model using pretrained embeddings Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-Fin6_wi1Rn",
        "outputId": "41d37bfa-2684-43f2-df37-b9dd4cc2837b"
      },
      "source": [
        "# Define feature extraction model using TF Hub layer\n",
        "\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding of each sequence (512 long vector)\n",
        "x = layers.Dense(128, activation='relu')(pretrained_embedding)\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name='model_2_USE_feature_extractor')\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_2.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_USE_feature_extractor\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pmkfxGQjzHA",
        "outputId": "a531cddf-9e88-466e-ddfc-87e02f040e22"
      },
      "source": [
        "# Fit model_2 to the data\n",
        "history_model_2 = model_2.fit(train_dataset, \n",
        "                              epochs = 3,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "                              validation_data = valid_dataset,\n",
        "                              validation_steps = int(0.1*len(valid_dataset)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 14s 19ms/step - loss: 0.9164 - accuracy: 0.6515 - val_loss: 0.7952 - val_accuracy: 0.6932\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.7703 - accuracy: 0.7012 - val_loss: 0.7566 - val_accuracy: 0.7015\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.7546 - accuracy: 0.7118 - val_loss: 0.7411 - val_accuracy: 0.7104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW3WqTqZkeNm",
        "outputId": "3484a20e-aada-4433-d195-2765a1901989"
      },
      "source": [
        "# Evaluate on the whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 15s 16ms/step - loss: 0.7428 - accuracy: 0.7123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7428109645843506, 0.7122997641563416]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3c_56Zjkk0H",
        "outputId": "6ac8191b-a6cb-4b5d-bd23-66b5151ce02b"
      },
      "source": [
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44396317, 0.34401533, 0.00302055, 0.19991963, 0.00908134],\n",
              "       [0.34984854, 0.4906592 , 0.00496534, 0.15096238, 0.00356449],\n",
              "       [0.22954625, 0.15449814, 0.01860199, 0.5578654 , 0.03948824],\n",
              "       ...,\n",
              "       [0.00231017, 0.00766817, 0.04479508, 0.00111466, 0.9441119 ],\n",
              "       [0.00419687, 0.04968099, 0.17183731, 0.00165473, 0.7726301 ],\n",
              "       [0.17616723, 0.23573019, 0.50771385, 0.00620111, 0.07418758]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc48DGpVkug3",
        "outputId": "e7a54432-cf31-46e9-c875-948f8a392712"
      },
      "source": [
        "# Convert the predictions probs with feature extraction model to label\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKMRWe0Ok4VW",
        "outputId": "75c3bff0-bd60-4c58-c811-e15d3863af60"
      },
      "source": [
        "# Calculate results from TF Hub pretrained embeddings on val set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred= model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.22997484443268,\n",
              " 'f1': 0.7095556763078315,\n",
              " 'precision': 0.713043773476309,\n",
              " 'recall': 0.7122997484443268}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGIXn2JylJcm"
      },
      "source": [
        "## Model 3: Conv1D with character embeddings\n",
        "\n",
        "The paper which we're replicating states they used a combination of token and character-level embeddings.\n",
        "\n",
        "Previously we've token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r-HXJCEl-Zn"
      },
      "source": [
        "## Creating a character-level tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fEaQr6gYmjTn",
        "outputId": "0db1decd-3e39-453a-ce14-607efde98639"
      },
      "source": [
        "# Make function to split sentences into characters\n",
        "\n",
        "def split_chars(text):\n",
        "    return ' '.join(list(text))\n",
        "\n",
        "# Text splitting non-character level sequence into characters\n",
        "split_chars(random_train_sentence)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a t   e a c h   s e s s i o n   ,   o c u l a r   f i x a t i o n   d a t a   w e r e   c o l l e c t e d   d u r i n g   p r e s e n t a t i o n   o f   v i d e o   s t i m u l i   o f   @   h u m a n   f a c e s   .'"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkNtHIXGmx6u"
      },
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBL8zdivnTXn",
        "outputId": "b1e432ab-4ed8-4bb3-a32f-71d932c28394"
      },
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "FFyiLfATnlBn",
        "outputId": "709dc8e1-c327-4166-d44f-dd2365125ee0"
      },
      "source": [
        "# Check the distribution of our sequences at a character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=20);"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk-yDwpVn3G_",
        "outputId": "1420fa15-e5ac-42b2-dc4d-81766aba3880"
      },
      "source": [
        "# Find what characte length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xCefoA-MoP9n",
        "outputId": "fce7c439-ff6c-4155-f129-b332877b7918"
      },
      "source": [
        "# Get all keyboard characters\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbzK9Jb7oHcH"
      },
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2  # add 2 for space and OOV token (OOV = out of vocab, '[UNK]')\n",
        "char_vectorizer = layers.TextVectorization(max_tokens = NUM_CHAR_TOKENS,\n",
        "                                            output_sequence_length = output_seq_char_len,\n",
        "                                           # standarize = None, # set standarization to 'None' if you want to leave puntuaction in\n",
        "                                            name = 'char_vectorizer')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgyZ89T1pd-A"
      },
      "source": [
        "# Adapt character vectorizer to training character\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNtSjDtLppwQ",
        "outputId": "63462104-06e2-4bb7-c055-025ac6137d6b"
      },
      "source": [
        "# Check character vocab stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f'Number of different characters in character vocab: {len(char_vocab)}')\n",
        "print(f'5 most common characters: {char_vocab[:5]}')\n",
        "print(f'5 least common characters: {char_vocab[-5:]}')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW_nVIJ4p_fH",
        "outputId": "519843cd-7982-4021-9ea5-29f1097db0a8"
      },
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f'Charified text:\\n {random_train_chars}')\n",
        "print(f'\\nLength of random_train_chars: {len(random_train_chars.split())}')\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f'\\nVectorized chars:\\n {vectorized_chars}')\n",
        "print(f'\\nLenght of vectorized chars:\\n {len(vectorized_chars[0])}')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " t o   a c h i e v e   b e t w e e n   a   @   %   a n d   @   %   p r o b a b i l i t y   o f   n o   g a g   r e s p o n s e   ,   p r o p o f o l   t c i s   w e r e   b e t w e e n   @   a n d   @   g m l   (   t h a t   c o u l d   b e   a c h i e v e d   w i t h   a   b o l u s   o f   @   m g k g   )   w h e n   r e m i f e n t a n i l   t c i   w a s   f i x e d   a t   @   n g m l   ,   a n d   t a r g e t   p r o p o f o l   t c i s   w e r e   b e t w e e n   @   a n d   @   g m l   (   t h a t   c o u l d   b e   a c h i e v e d   w i t h   a   b o l u s   o f   @   m g k g   )   w h e n   r e m i f e n t a n i l   t c i   w a s   f i x e d   a t   @   n g m l   .\n",
            "\n",
            "Length of random_train_chars: 268\n",
            "\n",
            "Vectorized chars:\n",
            " [[ 3  7  5 11 13  4  2 21  2 22  2  3 20  2  2  6  5  5  6 10 14  8  7 22\n",
            "   5 22  4 12  4  3 19  7 17  6  7 18  5 18  8  2  9 14  7  6  9  2 14  8\n",
            "   7 14  7 17  7 12  3 11  4  9 20  2  8  2 22  2  3 20  2  2  6  5  6 10\n",
            "  18 15 12  3 13  5  3 11  7 16 12 10 22  2  5 11 13  4  2 21  2 10 20  4\n",
            "   3 13  5 22  7 12 16  9  7 17 15 18 23 18 20 13  2  6  8  2 15  4 17  2\n",
            "   6  3  5  6  4 12  3 11  4 20  5  9 17  4 24  2 10  5  3  6 18 15 12  5\n",
            "   6 10  3  5  8 18  2  3 14  8  7 14  7 17  7 12  3 11  4  9 20  2  8  2\n",
            "  22  2  3 20  2  2  6  5  6 10 18 15 12  3 13  5  3 11  7 16 12 10 22  2\n",
            "   5 11 13  4  2 21  2 10 20  4  3 13  5 22  7 12 16  9  7 17 15 18 23 18\n",
            "  20 13  2  6  8  2 15  4 17  2  6  3  5  6  4 12  3 11  4 20  5  9 17  4\n",
            "  24  2 10  5  3  6 18 15 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Lenght of vectorized chars:\n",
            " 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGgPzYUMsIjP"
      },
      "source": [
        "## Creating a character-level embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tapji_ItrLQ5"
      },
      "source": [
        "# Create character-level embedding\n",
        "char_embed = layers.Embedding(input_dim=len(char_vocab),\n",
        "                              output_dim = 25, # Size of the char embedding in the paper\n",
        "                              mask_zero = True, \n",
        "                              name = 'character_embedding')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgT-vuF1sn_4",
        "outputId": "a167122c-5244-4f07-b742-37cac18e958f"
      },
      "source": [
        "# Test our character embedding layer\n",
        "print(f'Charified text:\\n {random_train_chars}\\n')\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f'Embedded chars (after vectorization and embeddings):\\n {char_embed_example}\\n')\n",
        "print(f'Char embedded shape:\\n {char_embed_example.shape}')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " t o   a c h i e v e   b e t w e e n   a   @   %   a n d   @   %   p r o b a b i l i t y   o f   n o   g a g   r e s p o n s e   ,   p r o p o f o l   t c i s   w e r e   b e t w e e n   @   a n d   @   g m l   (   t h a t   c o u l d   b e   a c h i e v e d   w i t h   a   b o l u s   o f   @   m g k g   )   w h e n   r e m i f e n t a n i l   t c i   w a s   f i x e d   a t   @   n g m l   ,   a n d   t a r g e t   p r o p o f o l   t c i s   w e r e   b e t w e e n   @   a n d   @   g m l   (   t h a t   c o u l d   b e   a c h i e v e d   w i t h   a   b o l u s   o f   @   m g k g   )   w h e n   r e m i f e n t a n i l   t c i   w a s   f i x e d   a t   @   n g m l   .\n",
            "\n",
            "Embedded chars (after vectorization and embeddings):\n",
            " [[[ 0.03736991  0.03544824  0.0295588  ...  0.0264699   0.0070375\n",
            "   -0.02411406]\n",
            "  [-0.01826826 -0.04781715  0.03328884 ...  0.0182214  -0.03101274\n",
            "    0.01900634]\n",
            "  [ 0.01375449  0.04624445  0.03747488 ... -0.01748512 -0.03055911\n",
            "   -0.02484497]\n",
            "  ...\n",
            "  [ 0.02980412  0.00835479  0.01115851 ... -0.00928466 -0.01925122\n",
            "   -0.01693111]\n",
            "  [ 0.02980412  0.00835479  0.01115851 ... -0.00928466 -0.01925122\n",
            "   -0.01693111]\n",
            "  [ 0.02980412  0.00835479  0.01115851 ... -0.00928466 -0.01925122\n",
            "   -0.01693111]]]\n",
            "\n",
            "Char embedded shape:\n",
            " (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw3Muk6etRK4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}